2024-12-11 12:59:06,448 - MainThread - sqlmesh.core.snapshot.evaluator - INFO - Listing data objects in schema "appex-data".zz_base_revenue (evaluator.py:282)
2024-12-11 12:59:06,454 - MainThread - sqlmesh.core.engine_adapter.base - INFO - Executing SQL: WITH `clustering_info` AS (SELECT `table_catalog`, `table_schema`, `table_name`, STRING_AGG(`column_name` ORDER BY `clustering_ordinal_position`) AS `clustering_key` FROM `appex-data`.`zz_base_revenue`.`INFORMATION_SCHEMA.COLUMNS` AS `COLUMNS` WHERE `clustering_ordinal_position` IS NOT NULL GROUP BY 1, 2, 3) SELECT `table_catalog` AS `catalog`, `table_name` AS `name`, `table_schema` AS `schema_name`, CASE WHEN `table_type` = 'BASE TABLE' THEN 'TABLE' WHEN `table_type` = 'CLONE' THEN 'TABLE' WHEN `table_type` = 'EXTERNAL' THEN 'TABLE' WHEN `table_type` = 'SNAPSHOT' THEN 'TABLE' WHEN `table_type` = 'VIEW' THEN 'VIEW' WHEN `table_type` = 'MATERIALIZED VIEW' THEN 'MATERIALIZED_VIEW' ELSE `table_type` END AS `type`, `ci`.`clustering_key` AS `clustering_key` FROM `appex-data`.`zz_base_revenue`.`INFORMATION_SCHEMA.TABLES` AS `TABLES` LEFT JOIN `clustering_info` AS `ci` USING (`table_catalog`, `table_schema`, `table_name`) WHERE `table_name` IN ('base_revenue__revenuecat__2603531060', 'base_revenue__adapty__1145941880', 'base_revenue__revenuecat__2603531060__temp') (base.py:2062)
2024-12-11 12:59:09,886 - MainThread - sqlmesh.core.snapshot.evaluator - INFO - Listing data objects in schema "appex-data".zz_base_product (evaluator.py:282)
2024-12-11 12:59:09,894 - MainThread - sqlmesh.core.engine_adapter.base - INFO - Executing SQL: WITH `clustering_info` AS (SELECT `table_catalog`, `table_schema`, `table_name`, STRING_AGG(`column_name` ORDER BY `clustering_ordinal_position`) AS `clustering_key` FROM `appex-data`.`zz_base_product`.`INFORMATION_SCHEMA.COLUMNS` AS `COLUMNS` WHERE `clustering_ordinal_position` IS NOT NULL GROUP BY 1, 2, 3) SELECT `table_catalog` AS `catalog`, `table_name` AS `name`, `table_schema` AS `schema_name`, CASE WHEN `table_type` = 'BASE TABLE' THEN 'TABLE' WHEN `table_type` = 'CLONE' THEN 'TABLE' WHEN `table_type` = 'EXTERNAL' THEN 'TABLE' WHEN `table_type` = 'SNAPSHOT' THEN 'TABLE' WHEN `table_type` = 'VIEW' THEN 'VIEW' WHEN `table_type` = 'MATERIALIZED VIEW' THEN 'MATERIALIZED_VIEW' ELSE `table_type` END AS `type`, `ci`.`clustering_key` AS `clustering_key` FROM `appex-data`.`zz_base_product`.`INFORMATION_SCHEMA.TABLES` AS `TABLES` LEFT JOIN `clustering_info` AS `ci` USING (`table_catalog`, `table_schema`, `table_name`) WHERE `table_name` IN ('base_product__appstore_connect_analytics_installs__2757015254__temp', 'base_product__appstore_connect_analytics_installs__2757015254') (base.py:2062)
2024-12-11 12:59:12,717 - MainThread - sqlmesh.core.snapshot.evaluator - INFO - Listing data objects in schema "appex-data".zz_core (evaluator.py:282)
2024-12-11 12:59:12,724 - MainThread - sqlmesh.core.engine_adapter.base - INFO - Executing SQL: WITH `clustering_info` AS (SELECT `table_catalog`, `table_schema`, `table_name`, STRING_AGG(`column_name` ORDER BY `clustering_ordinal_position`) AS `clustering_key` FROM `appex-data`.`zz_core`.`INFORMATION_SCHEMA.COLUMNS` AS `COLUMNS` WHERE `clustering_ordinal_position` IS NOT NULL GROUP BY 1, 2, 3) SELECT `table_catalog` AS `catalog`, `table_name` AS `name`, `table_schema` AS `schema_name`, CASE WHEN `table_type` = 'BASE TABLE' THEN 'TABLE' WHEN `table_type` = 'CLONE' THEN 'TABLE' WHEN `table_type` = 'EXTERNAL' THEN 'TABLE' WHEN `table_type` = 'SNAPSHOT' THEN 'TABLE' WHEN `table_type` = 'VIEW' THEN 'VIEW' WHEN `table_type` = 'MATERIALIZED VIEW' THEN 'MATERIALIZED_VIEW' ELSE `table_type` END AS `type`, `ci`.`clustering_key` AS `clustering_key` FROM `appex-data`.`zz_core`.`INFORMATION_SCHEMA.TABLES` AS `TABLES` LEFT JOIN `clustering_info` AS `ci` USING (`table_catalog`, `table_schema`, `table_name`) WHERE `table_name` IN ('core__sculptyou_commissions__3421614840__temp', 'core__sculptyou_commissions__3421614840') (base.py:2062)
2024-12-11 12:59:15,689 - MainThread - sqlmesh.core.snapshot.evaluator - INFO - Creating schema '"appex-data".zz_base_product' (evaluator.py:906)
2024-12-11 12:59:15,690 - MainThread - sqlmesh.core.engine_adapter.base - INFO - Executing SQL: CREATE SCHEMA IF NOT EXISTS `appex-data`.`zz_base_product` (base.py:2062)
2024-12-11 12:59:16,518 - MainThread - sqlmesh.core.snapshot.evaluator - INFO - Creating schema '"appex-data".zz_base_revenue' (evaluator.py:906)
2024-12-11 12:59:16,519 - MainThread - sqlmesh.core.engine_adapter.base - INFO - Executing SQL: CREATE SCHEMA IF NOT EXISTS `appex-data`.`zz_base_revenue` (base.py:2062)
2024-12-11 12:59:17,295 - MainThread - sqlmesh.core.snapshot.evaluator - INFO - Creating schema '"appex-data".zz_core' (evaluator.py:906)
2024-12-11 12:59:17,295 - MainThread - sqlmesh.core.engine_adapter.base - INFO - Executing SQL: CREATE SCHEMA IF NOT EXISTS `appex-data`.`zz_core` (base.py:2062)
2024-12-11 12:59:18,703 - MainThread - sqlmesh.core.renderer - WARNING - Column '"_file_name"' could not be resolved for model '"appex-data"."base_revenue"."revenuecat"', the column may not exist or is ambiguous (renderer.py:517)
2024-12-11 12:59:18,709 - MainThread - sqlmesh.core.snapshot.evaluator - INFO - Creating table '"appex-data".zz_base_revenue.base_revenue__revenuecat__2603531060__temp' (evaluator.py:1196)
2024-12-11 12:59:18,713 - MainThread - sqlmesh.core.engine_adapter.base - INFO - Executing SQL: CREATE TABLE IF NOT EXISTS `appex-data`.`zz_base_revenue`.`base_revenue__revenuecat__2603531060__temp` PARTITION BY `event_date` AS WITH `import_data` AS (SELECT *, `_file_name` AS `filename`, PARSE_DATE('%Y-%m-%d', SPLIT(`_file_name`, '/')[SAFE_OFFSET(4)]) AS `report_date`, SPLIT(SPLIT(SPLIT(`_file_name`, '/')[SAFE_OFFSET(5)], '_')[SAFE_OFFSET(1)], '.')[SAFE_OFFSET(0)] AS `report_timestamp` FROM `appex-data-imports`.`revenuecat_bucket`.`transactions` AS `transactions` WHERE FALSE), `dedupe_events` AS (SELECT `store_transaction_id` AS `transaction_id`, `rc_last_seen_app_user_id_alias` AS `user_id`, `original_store_transaction_id` AS `original_transaction_id`, CAST(MIN(CASE WHEN `store_transaction_id` = `original_store_transaction_id` THEN `start_time` END) OVER (PARTITION BY `original_store_transaction_id`) AS DATE) AS `original_transaction_date`, CAST(MIN(CASE WHEN `store_transaction_id` = `original_store_transaction_id` THEN `start_time` END) OVER (PARTITION BY `original_store_transaction_id`) AS TIMESTAMP) AS `original_transaction_ts`, CAST(`first_seen_time` AS DATE) AS `install_date`, CAST(`first_seen_time` AS TIMESTAMP) AS `install_ts`, CAST(`start_time` AS DATE) AS `event_date`, CAST(`start_time` AS TIMESTAMP) AS `event_ts`, CAST(MAX(`unsubscribe_detected_at`) OVER (PARTITION BY `store_transaction_id`) AS TIMESTAMP) AS `unsubscribe_detected_at`, CAST(MAX(`billing_issues_detected_at`) OVER (PARTITION BY `store_transaction_id`) AS TIMESTAMP) AS `billing_issues_detected_at`, DATE_DIFF(`start_time`, `first_seen_time`, DAY) AS `install_age`, `store`, `country`, `platform`, `product_identifier`, `product_duration`, `renewal_number`, `price_in_usd`, `report_date`, `is_trial_conversion`, `is_trial_period`, `is_sandbox`, ROW_NUMBER() OVER (PARTITION BY `store_transaction_id` ORDER BY `report_date` DESC) AS `rn` FROM `import_data` AS `import_data` WHERE (TRUE AND `is_sandbox` = FALSE) AND FALSE) SELECT * EXCEPT (`rn`), MIN(CASE WHEN `price_in_usd` > 0 THEN `renewal_number` END) OVER (PARTITION BY `original_transaction_id`) = `renewal_number` AS `is_first_usd_renewal` FROM `dedupe_events` AS `dedupe_events` WHERE `rn` = 1 AND FALSE LIMIT 0 (base.py:2062)
2024-12-11 12:59:23,481 - MainThread - sqlmesh.core.snapshot.evaluator - INFO - Evaluating snapshot SnapshotId<"appex-data"."base_revenue"."adapty": 2854870668> (evaluator.py:508)
2024-12-11 12:59:24,159 - MainThread - sqlmesh.core.renderer - WARNING - Column '"_file_name"' could not be resolved for model '"appex-data"."base_revenue"."adapty"', the column may not exist or is ambiguous (renderer.py:517)
2024-12-11 12:59:24,166 - MainThread - sqlmesh.core.snapshot.evaluator - INFO - Inserting batch (2020-01-01 00:00:00+00:00, 2024-12-10 00:00:00+00:00) into "appex-data".zz_base_revenue.base_revenue__adapty__1145941880' (evaluator.py:538)
2024-12-11 12:59:24,543 - MainThread - sqlmesh.core.engine_adapter.base - INFO - Executing SQL: CREATE OR REPLACE TABLE `appex-data`.`zz_base_revenue`.`base_revenue__adapty__1145941880` (`profile_id` STRING OPTIONS (description='events.*'), `event_type` STRING, `event_ts` TIMESTAMP, `event_date` DATE, `transaction_id` INT64, `original_transaction_id` INT64, `subscription_expires_at` TIMESTAMP, `environment` STRING, `revenue_usd` FLOAT64, `proceeds_usd` FLOAT64, `net_revenue_usd` FLOAT64, `tax_amount_usd` FLOAT64, `revenue_local` FLOAT64, `cancellation_reason` STRING, `proceeds_local` FLOAT64, `net_revenue_local` FLOAT64, `tax_amount_local` FLOAT64, `customer_user_id` STRING, `store` STRING, `product_id` STRING, `developer_id` STRING, `ab_test_name` STRING, `ab_test_revision` INT64, `paywall_name` STRING, `paywall_revision` INT64, `profile_country` STRING, `install_date` TIMESTAMP, `idfv` STRING, `idfa` STRING, `advertising_id` STRING, `ip_address` STRING, `android_app_set_id` STRING, `android_id` STRING, `device` STRING, `currency` STRING, `store_country` STRING, `attribution_source` STRING, `attribution_network_user_id` STRING, `attribution_status` STRING, `attribution_channel` STRING, `attribution_campaign` STRING, `attribution_ad_group` STRING, `attribution_ad_set` STRING, `attribution_creative` STRING, `original_transaction_date` DATE, `original_transaction_ts` TIMESTAMP, `filename` STRING, `gcs_folder` STRING, `adapty_id` STRING, `report_date` DATE, `app_id` STRING, `app_name` STRING) PARTITION BY `event_date` OPTIONS (require_partition_filter=TRUE) AS SELECT CAST(`profile_id` AS STRING) AS `profile_id`, CAST(`event_type` AS STRING) AS `event_type`, CAST(`event_ts` AS TIMESTAMP) AS `event_ts`, CAST(`event_date` AS DATE) AS `event_date`, CAST(`transaction_id` AS INT64) AS `transaction_id`, CAST(`original_transaction_id` AS INT64) AS `original_transaction_id`, CAST(`subscription_expires_at` AS TIMESTAMP) AS `subscription_expires_at`, CAST(`environment` AS STRING) AS `environment`, CAST(`revenue_usd` AS FLOAT64) AS `revenue_usd`, CAST(`proceeds_usd` AS FLOAT64) AS `proceeds_usd`, CAST(`net_revenue_usd` AS FLOAT64) AS `net_revenue_usd`, CAST(`tax_amount_usd` AS FLOAT64) AS `tax_amount_usd`, CAST(`revenue_local` AS FLOAT64) AS `revenue_local`, CAST(`cancellation_reason` AS STRING) AS `cancellation_reason`, CAST(`proceeds_local` AS FLOAT64) AS `proceeds_local`, CAST(`net_revenue_local` AS FLOAT64) AS `net_revenue_local`, CAST(`tax_amount_local` AS FLOAT64) AS `tax_amount_local`, CAST(`customer_user_id` AS STRING) AS `customer_user_id`, CAST(`store` AS STRING) AS `store`, CAST(`product_id` AS STRING) AS `product_id`, CAST(`developer_id` AS STRING) AS `developer_id`, CAST(`ab_test_name` AS STRING) AS `ab_test_name`, CAST(`ab_test_revision` AS INT64) AS `ab_test_revision`, CAST(`paywall_name` AS STRING) AS `paywall_name`, CAST(`paywall_revision` AS INT64) AS `paywall_revision`, CAST(`profile_country` AS STRING) AS `profile_country`, CAST(`install_date` AS TIMESTAMP) AS `install_date`, CAST(`idfv` AS STRING) AS `idfv`, CAST(`idfa` AS STRING) AS `idfa`, CAST(`advertising_id` AS STRING) AS `advertising_id`, CAST(`ip_address` AS STRING) AS `ip_address`, CAST(`android_app_set_id` AS STRING) AS `android_app_set_id`, CAST(`android_id` AS STRING) AS `android_id`, CAST(`device` AS STRING) AS `device`, CAST(`currency` AS STRING) AS `currency`, CAST(`store_country` AS STRING) AS `store_country`, CAST(`attribution_source` AS STRING) AS `attribution_source`, CAST(`attribution_network_user_id` AS STRING) AS `attribution_network_user_id`, CAST(`attribution_status` AS STRING) AS `attribution_status`, CAST(`attribution_channel` AS STRING) AS `attribution_channel`, CAST(`attribution_campaign` AS STRING) AS `attribution_campaign`, CAST(`attribution_ad_group` AS STRING) AS `attribution_ad_group`, CAST(`attribution_ad_set` AS STRING) AS `attribution_ad_set`, CAST(`attribution_creative` AS STRING) AS `attribution_creative`, CAST(`original_transaction_date` AS DATE) AS `original_transaction_date`, CAST(`original_transaction_ts` AS TIMESTAMP) AS `original_transaction_ts`, CAST(`filename` AS STRING) AS `filename`, CAST(`gcs_folder` AS STRING) AS `gcs_folder`, CAST(`adapty_id` AS STRING) AS `adapty_id`, CAST(`report_date` AS DATE) AS `report_date`, CAST(`app_id` AS STRING) AS `app_id`, CAST(`app_name` AS STRING) AS `app_name` FROM (SELECT `profile_id` AS `profile_id`, `event_type` AS `event_type`, `event_datetime` AS `event_ts`, CAST(`event_datetime` AS DATE) AS `event_date`, `transaction_id` AS `transaction_id`, `original_transaction_id` AS `original_transaction_id`, `subscription_expires_at` AS `subscription_expires_at`, `environment` AS `environment`, `revenue_usd` AS `revenue_usd`, `proceeds_usd` AS `proceeds_usd`, `net_revenue_usd` AS `net_revenue_usd`, `tax_amount_usd` AS `tax_amount_usd`, `revenue_local` AS `revenue_local`, `cancellation_reason` AS `cancellation_reason`, `proceeds_local` AS `proceeds_local`, `net_revenue_local` AS `net_revenue_local`, `tax_amount_local` AS `tax_amount_local`, `customer_user_id` AS `customer_user_id`, `store` AS `store`, `product_id` AS `product_id`, `developer_id` AS `developer_id`, `ab_test_name` AS `ab_test_name`, `ab_test_revision` AS `ab_test_revision`, `paywall_name` AS `paywall_name`, `paywall_revision` AS `paywall_revision`, `profile_country` AS `profile_country`, `install_date` AS `install_date`, `idfv` AS `idfv`, `idfa` AS `idfa`, `advertising_id` AS `advertising_id`, `ip_address` AS `ip_address`, `android_app_set_id` AS `android_app_set_id`, `android_id` AS `android_id`, `device` AS `device`, `currency` AS `currency`, `store_country` AS `store_country`, `attribution_source` AS `attribution_source`, `attribution_network_user_id` AS `attribution_network_user_id`, `attribution_status` AS `attribution_status`, `attribution_channel` AS `attribution_channel`, `attribution_campaign` AS `attribution_campaign`, `attribution_ad_group` AS `attribution_ad_group`, `attribution_ad_set` AS `attribution_ad_set`, `attribution_creative` AS `attribution_creative`, CAST(MIN(CASE WHEN `events`.`transaction_id` = `events`.`original_transaction_id` THEN `events`.`event_datetime` END) OVER (PARTITION BY `events`.`original_transaction_id`) AS DATE) AS `original_transaction_date`, CAST(MIN(CASE WHEN `events`.`transaction_id` = `events`.`original_transaction_id` THEN `events`.`event_datetime` END) OVER (PARTITION BY `events`.`original_transaction_id`) AS TIMESTAMP) AS `original_transaction_ts`, `_file_name` AS `filename`, SPLIT(SPLIT(`_file_name`, '/')[SAFE_OFFSET(3)], '/')[SAFE_OFFSET(0)] AS `gcs_folder`, SPLIT(SPLIT(`_file_name`, '/')[SAFE_OFFSET(4)], '_')[SAFE_OFFSET(0)] AS `adapty_id`, PARSE_DATE('%Y-%m-%d', SPLIT(SPLIT(SPLIT(`_file_name`, '/')[SAFE_OFFSET(4)], '_')[SAFE_OFFSET(1)], '.')[SAFE_OFFSET(0)]) AS `report_date`, `map`.`app_id` AS `app_id`, `map`.`app_name` AS `app_name` FROM `appex-data-imports`.`adapty_bucket`.`events` AS `events` LEFT JOIN `appex-data`.`base`.`app_ids` AS `map` ON `map`.`adapty_id` = SPLIT(SPLIT(`_file_name`, '/')[SAFE_OFFSET(4)], '_')[SAFE_OFFSET(0)] WHERE `events`.`environment` = 'Production') AS `_subquery` (base.py:2062)
2024-12-11 13:00:22,148 - MainThread - sqlmesh.core.snapshot.evaluator - INFO - Auditing snapshot SnapshotId<"appex-data"."base_revenue"."adapty": 2854870668> (evaluator.py:428)
2024-12-11 13:00:22,840 - MainThread - sqlmesh.core.engine_adapter.base - INFO - Executing SQL: SELECT COUNT(*) FROM (SELECT * FROM (SELECT * FROM `appex-data`.`zz_base_revenue`.`base_revenue__adapty__1145941880` AS `base_revenue__adapty__1145941880`) AS `_q_0` WHERE (`transaction_id` IS NULL OR `original_transaction_id` IS NULL OR `event_date` IS NULL OR `report_date` IS NULL) AND TRUE) AS `audit` (base.py:2062)
2024-12-11 13:00:23,476 - MainThread - sqlmesh.core.snapshot.evaluator - INFO - Evaluating snapshot SnapshotId<"appex-data"."base_revenue"."revenuecat": 3130017860> (evaluator.py:508)
2024-12-11 13:00:24,290 - MainThread - sqlmesh.core.renderer - WARNING - Column '"_file_name"' could not be resolved for model '"appex-data"."base_revenue"."revenuecat"', the column may not exist or is ambiguous (renderer.py:517)
2024-12-11 13:00:24,294 - MainThread - sqlmesh.core.snapshot.evaluator - INFO - Inserting batch (2020-01-01 00:00:00+00:00, 2024-11-20 00:00:00+00:00) into "appex-data".zz_base_revenue.base_revenue__revenuecat__2603531060' (evaluator.py:538)
2024-12-11 13:00:24,634 - MainThread - sqlmesh.core.engine_adapter.base - INFO - Executing SQL: CREATE OR REPLACE TABLE `appex-data`.`zz_base_revenue`.`base_revenue__revenuecat__2603531060` PARTITION BY `event_date` AS WITH `import_data` AS (SELECT *, `_file_name` AS `filename`, PARSE_DATE('%Y-%m-%d', SPLIT(`_file_name`, '/')[SAFE_OFFSET(4)]) AS `report_date`, SPLIT(SPLIT(SPLIT(`_file_name`, '/')[SAFE_OFFSET(5)], '_')[SAFE_OFFSET(1)], '.')[SAFE_OFFSET(0)] AS `report_timestamp` FROM `appex-data-imports`.`revenuecat_bucket`.`transactions` AS `transactions`), `dedupe_events` AS (SELECT `store_transaction_id` AS `transaction_id`, `rc_last_seen_app_user_id_alias` AS `user_id`, `original_store_transaction_id` AS `original_transaction_id`, CAST(MIN(CASE WHEN `store_transaction_id` = `original_store_transaction_id` THEN `start_time` END) OVER (PARTITION BY `original_store_transaction_id`) AS DATE) AS `original_transaction_date`, CAST(MIN(CASE WHEN `store_transaction_id` = `original_store_transaction_id` THEN `start_time` END) OVER (PARTITION BY `original_store_transaction_id`) AS TIMESTAMP) AS `original_transaction_ts`, CAST(`first_seen_time` AS DATE) AS `install_date`, CAST(`first_seen_time` AS TIMESTAMP) AS `install_ts`, CAST(`start_time` AS DATE) AS `event_date`, CAST(`start_time` AS TIMESTAMP) AS `event_ts`, CAST(MAX(`unsubscribe_detected_at`) OVER (PARTITION BY `store_transaction_id`) AS TIMESTAMP) AS `unsubscribe_detected_at`, CAST(MAX(`billing_issues_detected_at`) OVER (PARTITION BY `store_transaction_id`) AS TIMESTAMP) AS `billing_issues_detected_at`, DATE_DIFF(`start_time`, `first_seen_time`, DAY) AS `install_age`, `store`, `country`, `platform`, `product_identifier`, `product_duration`, `renewal_number`, `price_in_usd`, `report_date`, `is_trial_conversion`, `is_trial_period`, `is_sandbox`, ROW_NUMBER() OVER (PARTITION BY `store_transaction_id` ORDER BY `report_date` DESC) AS `rn` FROM `import_data` AS `import_data` WHERE TRUE AND `is_sandbox` = FALSE) SELECT CAST(`transaction_id` AS STRING) AS `transaction_id`, CAST(`user_id` AS STRING) AS `user_id`, CAST(`original_transaction_id` AS STRING) AS `original_transaction_id`, CAST(`original_transaction_date` AS DATE) AS `original_transaction_date`, CAST(`original_transaction_ts` AS TIMESTAMP) AS `original_transaction_ts`, CAST(`install_date` AS DATE) AS `install_date`, CAST(`install_ts` AS TIMESTAMP) AS `install_ts`, CAST(`event_date` AS DATE) AS `event_date`, CAST(`event_ts` AS TIMESTAMP) AS `event_ts`, CAST(`unsubscribe_detected_at` AS TIMESTAMP) AS `unsubscribe_detected_at`, CAST(`billing_issues_detected_at` AS TIMESTAMP) AS `billing_issues_detected_at`, CAST(`install_age` AS INT64) AS `install_age`, CAST(`store` AS STRING) AS `store`, CAST(`country` AS STRING) AS `country`, CAST(`platform` AS STRING) AS `platform`, CAST(`product_identifier` AS STRING) AS `product_identifier`, CAST(`product_duration` AS STRING) AS `product_duration`, CAST(`renewal_number` AS INT64) AS `renewal_number`, CAST(`price_in_usd` AS FLOAT64) AS `price_in_usd`, CAST(`report_date` AS DATE) AS `report_date`, CAST(`is_trial_conversion` AS BOOL) AS `is_trial_conversion`, CAST(`is_trial_period` AS BOOL) AS `is_trial_period`, CAST(`is_sandbox` AS BOOL) AS `is_sandbox`, CAST(`is_first_usd_renewal` AS BOOL) AS `is_first_usd_renewal` FROM (SELECT * EXCEPT (`rn`), MIN(CASE WHEN `price_in_usd` > 0 THEN `renewal_number` END) OVER (PARTITION BY `original_transaction_id`) = `renewal_number` AS `is_first_usd_renewal` FROM `dedupe_events` AS `dedupe_events` WHERE `rn` = 1) AS `_subquery` (base.py:2062)
2024-12-11 13:01:27,957 - MainThread - sqlmesh.core.snapshot.evaluator - INFO - Auditing snapshot SnapshotId<"appex-data"."base_revenue"."revenuecat": 3130017860> (evaluator.py:428)
2024-12-11 13:01:28,383 - MainThread - sqlmesh.core.engine_adapter.base - INFO - Executing SQL: SELECT COUNT(*) FROM (SELECT * FROM (SELECT * FROM `appex-data`.`zz_base_revenue`.`base_revenue__revenuecat__2603531060` AS `base_revenue__revenuecat__2603531060`) AS `_q_0` WHERE (`transaction_id` IS NULL OR `original_transaction_id` IS NULL OR `event_date` IS NULL OR `report_date` IS NULL) AND TRUE) AS `audit` (base.py:2062)
2024-12-11 13:01:35,092 - MainThread - sqlmesh.core.state_sync.engine_adapter - INFO - Adding interval (1577836800000, 1732060800000) for snapshot SnapshotId<"appex-data"."base_revenue"."revenuecat": 3130017860> (engine_adapter.py:933)
2024-12-11 13:01:35,448 - MainThread - sqlmesh.core.scheduler - INFO - FAILED processing snapshot "appex-data"."base_revenue"."adapty"
Traceback (most recent call last):
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/sqlmesh/utils/concurrency.py", line 227, in sequential_apply_to_dag
    fn(node)
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/sqlmesh/core/scheduler.py", line 423, in evaluate_node
    self.evaluate(snapshot, start, end, execution_time, deployability_index, batch_idx)
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/sqlmesh/core/scheduler.py", line 247, in evaluate
    audit_results = self.snapshot_evaluator.audit(
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/sqlmesh/core/snapshot/evaluator.py", line 432, in audit
    self._audit(
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/sqlmesh/core/snapshot/evaluator.py", line 875, in _audit
    count, *_ = self.adapter.fetchone(
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/sqlmesh/core/engine_adapter/bigquery.py", line 296, in fetchone
    self.execute(
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/sqlmesh/core/engine_adapter/base.py", line 2059, in execute
    self._execute(sql, **kwargs)
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/sqlmesh/core/engine_adapter/bigquery.py", line 867, in _execute
    results = self._db_call(
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/sqlmesh/core/engine_adapter/bigquery.py", line 825, in _db_call
    return func(
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py", line 1675, in result
    while not is_job_done():
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py", line 293, in retry_wrapped_func
    return retry_target(
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py", line 153, in retry_target
    _retry_error_helper(
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/google/api_core/retry/retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py", line 144, in retry_target
    result = target()
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py", line 1624, in is_job_done
    raise job_failed_exception
google.api_core.exceptions.BadRequest: 400 Cannot query over table 'appex-data.zz_base_revenue.base_revenue__adapty__1145941880' without a filter over column(s) 'event_date' that can be used for partition elimination; reason: invalidQuery, location: query, message: Cannot query over table 'appex-data.zz_base_revenue.base_revenue__adapty__1145941880' without a filter over column(s) 'event_date' that can be used for partition elimination

Location: US
Job ID: 5d55e54f-b468-4bcc-9abc-7a7cde1f2139

 (scheduler.py:379)
2024-12-11 13:01:35,449 - MainThread - sqlmesh.core.context - ERROR - Apply Failure: Traceback (most recent call last):
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/sqlmesh/core/context.py", line 1362, in apply
    self._apply(plan, circuit_breaker)
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/sqlmesh/core/context.py", line 1906, in _apply
    self._scheduler.create_plan_evaluator(self).evaluate(
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/sqlmesh/core/plan/evaluator.py", line 120, in evaluate
    self._backfill(
  File "/opt/homebrew/Caskroom/miniforge/base/envs/python310/lib/python3.10/site-packages/sqlmesh/core/plan/evaluator.py", line 200, in _backfill
    raise SQLMeshError("Plan application failed.")
sqlmesh.utils.errors.SQLMeshError: Plan application failed.
 (context.py:1370)
2024-12-11 13:01:35,456 - MainThread - root - INFO - Shutting down the event dispatcher (dispatcher.py:159)
